{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read earnings reports (OO version)\n",
    "\n",
    "E. Quinn 12/22/2019\n",
    "\n",
    "This notebook uses pdfminer to extract the information from the individual earnings report\n",
    "\n",
    "The documentation for pdfminer is at:\n",
    "\n",
    "https://buildmedia.readthedocs.org/media/pdf/pdfminer-docs/latest/pdfminer-docs.pdf\n",
    "\n",
    "Maintenance:\n",
    "\n",
    "* 3/6/2020  \n",
    "  * Add check date and number\n",
    "* 3/7/2020  \n",
    "  * Align personnel classes with support professionals structure\n",
    "  * Implement salary step capture for support professionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import standard python datascience packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "from datascience import *\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pdfminer packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LTTextBoxHorizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the directory we are running in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gquinn/EG/school_committee/finance_subcommittee/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pdf and create a dictionary with the contents of each text box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function read_pdf() reads a PDF and returns a dictionary containing the contents\n",
    "\n",
    "Strategy for this document:  \n",
    "\n",
    "Save information from each element in the LTTextBox objects in a dictionary including:\n",
    "\n",
    "- x0 horizontal coordinate of the upper left corner of the text box\n",
    "- x1 horizontal coordinate of the lower right corner of the text box\n",
    "- y0 vertical coordinate of the upper left corner of the text box\n",
    "- y1 vertical coordinate of the lower right corner of the text box\n",
    "- page number \n",
    "- sequence number of text box within this page\n",
    "- text contained in the text box, converted to ascii\n",
    "\n",
    "Parsing the text is complicated by the fact that that a text box may span multiple columns and/or rows, and the text box groupings vary quite a bit depending on the page contents and layout.\n",
    "\n",
    "However, with a bit of luck the structure of the document will allow the contents to be deciphered with the following heuristics:\n",
    "\n",
    "- Text boxes containing left justified columns will tend to have nearly the same x0 coordinates\n",
    "- Text boxes containing right justified columns will tend to have nearly the same x1 coordinates\n",
    "- The codes for fund, account code, and object code are numeric and have fixed lengths\n",
    "- Extraneous information is often preceded or followed by a series of underscore and newline characters\n",
    "- Last name can be distinguished because is the only field that is all characters followed by a comma\n",
    "- Last name may be preceded by between one and three numerical fields:  fund, account, object.  If it is, the x0 value is shifted to the left.\n",
    "    - Three numerical fields precede the name:  assume they are fund, account, object\n",
    "    - Two numerical fields precede the name: assume they are account, object\n",
    "    - One numerical field precedes the name: assume it is object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    document = open(path, 'rb')                                     #read a pdf and create a document object\n",
    "    rsrcmgr = PDFResourceManager()                                  #create a resource manager\n",
    "    laparams = LAParams()                                           #set the parameters for analysis\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)          #create a PDF page aggregator object\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    pdf={}                                                          #dictionary to hold the results\n",
    "\n",
    "    pageno = -1                                                     #initialize page coounter to zero\n",
    "\n",
    "    for page in PDFPage.get_pages(document):                        #loop through the pdf page by page\n",
    "        pageno = pageno + 1                                         #increment the page number\n",
    "        pdf[pageno] = {}                                            #dictionary for this page\n",
    "        interpreter.process_page(page)                              # receive the LTPage object for the page.\n",
    "        layout = device.get_result()                                # create layout object\n",
    "        tbox_no=0                                                   # index for element number\n",
    "        for element in layout:\n",
    "            if (type(element).__name__=='LTTextBoxHorizontal'):     #loop through text boxes\n",
    "                tbox_no += 1                                        #increment text box number\n",
    "                pdf[pageno][tbox_no] = {}                           #dictionary for text boxes within page\n",
    "                x0 = round(element.x0,2)                            #x0 coordinate of textbox corner\n",
    "                x1 = round(element.x1,2)                            #x1 coordinate of textbox corner\n",
    "                y0 = round(element.y0,2)                            #y0 coordinate of textbox corner\n",
    "                y1 = round(element.y1,2)                            #y1 coordinate of textbox corner\n",
    "                txt = element.get_text().encode('ascii', 'ignore')  #text converted to ascii\n",
    "                pdf[pageno][tbox_no]['x0'] = x0                     #create x0 coordinate entry\n",
    "                pdf[pageno][tbox_no]['x1'] = x1                     #create x1 coordinate entry\n",
    "                pdf[pageno][tbox_no]['y0'] = y0                     #create y0 coordinate entry\n",
    "                pdf[pageno][tbox_no]['y1'] = y1                     #create y1 coordinate entry\n",
    "\n",
    "                pdf[pageno][tbox_no]['text'] = ''.join(chr(c) for c in txt) #convert bytes to string\n",
    "    return(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the commas from earnings and rate values\n",
    "\n",
    "def remove_commas(st):\n",
    "    newstr = st.replace(',','')                     #remove commas from string\n",
    "    return(newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the headings fields \n",
    "\n",
    "def remove_headings(st):\n",
    "    lines = st.split('\\n')                         #split the string at newline characters '\\n'\n",
    "    for line in lines:                             #loop through the resulting lines\n",
    "        if (line.startswith('FUND ') |\\\n",
    "           (line.startswith('POSITION')) |\\\n",
    "           (line.startswith('RATE')) |\\\n",
    "           (line.startswith('ACCT-')) |\\\n",
    "           (line.startswith('CHECK')) |\\\n",
    "           (line.startswith('_'))):                #check for strings that appear only in headings\n",
    "            try:\n",
    "                newline_index = st.index('\\n')     #if present, remove this line from the text string\n",
    "                st = st[newline_index+1:]\n",
    "            except ValueError:\n",
    "                print('Value Error',st)            #recover from Value Error and print string\n",
    "        else:\n",
    "            return(st)                             #if no headings, just return\n",
    "    return('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the FY2017 earnings report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p17 = read_pdf('../FY17 Gene_Redacted.pdf')\n",
    "p17 = read_pdf('../FY17 Gene.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the FY2018 earnings report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p18 = read_pdf('../FY18 Gene_Redacted.pdf')\n",
    "p18 = read_pdf('../FY18 Gene.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dictionary with only those text boxes containing names\n",
    "\n",
    "Use the following algorithm to identify text boxes that contain names:\n",
    "\n",
    "- x0, horizontal coordinate of the upper left corner of the text box, is less than 162\n",
    "- the text string contains at least one comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(dct):\n",
    "\n",
    "    dnames = {}\n",
    "\n",
    "    fund = ''\n",
    "    acct = ''\n",
    "    obj  = ''\n",
    "    \n",
    "    for page in sorted(dct.keys()):                                #loop through text box dictionary by page # \n",
    "        if (page not in dnames.keys()):                            #page number is highest level key\n",
    "            dnames[page] = {}                                      #initialize entry for this page\n",
    "        for tb in sorted(dct[page].keys()):                        #loop through all text boxes on this page\n",
    "            if (dct[page][tb]['x0'] < 162.0):                      #those with names start to the left of x0=162\n",
    "                txt = str(dct[page][tb]['text'])                   #convert the 'text' element to a string\n",
    "                if (',' in txt):                                   #every name contains a comma\n",
    "                    txt = remove_headings(txt)\n",
    "                    lines = txt.split('\\n')                        #split text into lines\n",
    "                    words = lines[0].split()                       #split first line into words\n",
    "                    for word in words:                             #loop through and strip out fund, acct, obj\n",
    "                        if (word.isdigit()):\n",
    "                            if (len(word)==4):                     # 4 digits means fund\n",
    "                                fund = word\n",
    "                            if (len(word)==8):                     # 8 digits means acct-code\n",
    "                                acct = word\n",
    "                            if (len(word)==5):                     # 5 digits means obj\n",
    "                                obj = word\n",
    "                            txt = txt[len(word)+1:]                # remove fund/acct/obj from txt\n",
    "                    dnames[page][tb] = {}                          #initialize dictionary for this page\n",
    "                    dnames[page][tb]['x0'] = dct[page][tb]['x0']\n",
    "                    dnames[page][tb]['x1'] = dct[page][tb]['x1']\n",
    "                    dnames[page][tb]['y0'] = dct[page][tb]['y0']\n",
    "                    dnames[page][tb]['y1'] = dct[page][tb]['y1']\n",
    "                    dnames[page][tb]['fund'] = fund\n",
    "                    dnames[page][tb]['acct'] = acct\n",
    "                    dnames[page][tb]['obj'] = obj\n",
    "                    dnames[page][tb]['text'] = txt\n",
    "    return(dnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate text boxes that overlap on the vertical scale and contain names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_name_boxes(names):\n",
    "    newnames = {}\n",
    "    \n",
    "    for page in sorted(names.keys()):                                        #loop through pages of pdf\n",
    "        newnames[page] = {}                                                  #initialize new names dictionary\n",
    "        skip = make_array()                                                  #initialize list of boxes to skip\n",
    "    \n",
    "        for tb in sorted(names[page].keys()):                                #loop through text boxes on this page\n",
    "            for tb2 in sorted(names[page].keys()):                           #compare this one to the others\n",
    "                if ((tb2 > tb) & \\\n",
    "                    (names[page][tb]['y0'] <= names[page][tb2]['y1']) & \\\n",
    "                    (names[page][tb2]['y0'] <= names[page][tb]['y1'])):      \n",
    "                    d = {}                                                   #initialize replacement entry\n",
    "                    d['x0'] = names[page][tb]['x0']                          #keep x0    \n",
    "                    d['x1'] = names[page][tb2]['x1']                         #replace x1 with tb2 value\n",
    "                    d['y0'] = names[page][tb2]['y0']                         #replace y0 with tb2 value\n",
    "                    d['y1'] = names[page][tb]['y1']                          #keep y1 value\n",
    "                    d['text'] = names[page][tb]['text'] +\\\n",
    "                        names[page][tb2]['text']                             #contatenate text strings\n",
    "                    d['fund'] = names[page][tb]['fund']                      #copy fund, acct, and obj\n",
    "                    d['acct'] = names[page][tb]['acct']\n",
    "                    d['obj'] = names[page][tb]['obj']\n",
    "                    newnames[page][tb2] = d                                  #plug into dictionary\n",
    "                    skip = np.append(skip,tb)                                #add old boxes to skip list\n",
    "                    skip = np.append(skip,tb2)\n",
    "            if (tb not in skip):                                             #if no match, check skip list \n",
    "                newnames[page][tb] = names[page][tb]                         #just copy if not in skip list\n",
    "                    \n",
    "    return(newnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combdd(cn,pdf):\n",
    "    \n",
    "    dd = {}\n",
    "    \n",
    "    for page in sorted(cn.keys()):\n",
    "        if page not in dd.keys():\n",
    "            dd[page] = {}\n",
    "        for tb in sorted(cn[page].keys()):                               #loop through consolidated name textboxes\n",
    "            dd[page][tb] = cn[page][tb]\n",
    "            y0  = dd[page][tb]['y0']                                      #extract vertical coordinates\n",
    "            y1  = dd[page][tb]['y1']\n",
    "            txt = dd[page][tb]['text']                           #extract text\n",
    "            for tb2 in sorted(pdf[page].keys()):                            #loop through the other boxes in pdf\n",
    "                if (tb != tb2):                                             #ignore if same box as names\n",
    "                    tx0 = pdf[page][tb2]['x0']                              #get horizontal offset\n",
    "                    ty0 = pdf[page][tb2]['y0']                              #check whether the vertical \n",
    "                    ty1 = pdf[page][tb2]['y1']                              #range of this box overlaps that\n",
    "                    if ((y0 <= ty1) & (ty0 <= y1)):                         #of the name box\n",
    "                        txt = remove_headings(pdf[page][tb2]['text'])\n",
    "                        if ((312.0 < tx0) & (tx0 < 316.0)):                 #match to DATE/NUMBER\n",
    "                            dd[page][tb]['numbers1'] = txt\n",
    "                        if ((383.0 < tx0) & (tx0 < 395.0)):                 #match to NUMBER\n",
    "                            if 'numbers2' not in dd[page][tb].keys():\n",
    "                                dd[page][tb]['numbers2'] = txt\n",
    "                            else:\n",
    "                                dd[page][tb]['numbers2'] += txt\n",
    "                        if ((437.0 < tx0) & (tx0 < 440.0)):                 #match to POSITION\n",
    "                            dd[page][tb]['positions'] = txt\n",
    "                        if ((509.0 < tx0) & (tx0 < 533.0)):                 #match to RATE \n",
    "                            dd[page][tb]['rates'] = remove_commas(txt)\n",
    "                        if ((558.0 < tx0) & (tx0 < 630.0)):                 #match to ACCT-EARNINGS\n",
    "                            dd[page][tb]['earnings'] = remove_commas(txt)\n",
    "\n",
    "    return(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(nn):\n",
    "    \n",
    "    lld = {}\n",
    "    \n",
    "    for page in sorted(nn.keys()):\n",
    "        if page not in lld.keys():\n",
    "            lld[page] = {}\n",
    "        for tb in sorted(nn[page].keys()):\n",
    "            if tb not in lld[page].keys():\n",
    "                lld[page][tb]              = {}\n",
    "                lld[page][tb]['names']     = []\n",
    "                lld[page][tb]['checks']    = []\n",
    "                lld[page][tb]['dates']     = []\n",
    "                lld[page][tb]['rates']     = []\n",
    "                lld[page][tb]['earnings']  = []\n",
    "                lld[page][tb]['positions'] = []\n",
    "                lld[page][tb]['fund']      = ''\n",
    "                lld[page][tb]['acct']      = ''\n",
    "                lld[page][tb]['obj']       = ''\n",
    "            txt = nn[page][tb]['text']\n",
    "            words = txt.split('\\n')\n",
    "            for word in words:\n",
    "                if (len(word) > 1):\n",
    "                    lld[page][tb]['names'].append(word)\n",
    "            if 'numbers1' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['numbers1']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if word.isdigit():\n",
    "                        lld[page][tb]['checks'].append(word)\n",
    "                    elif '/' in word:\n",
    "                        lld[page][tb]['dates'].append(word)\n",
    "            if 'numbers2' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['numbers2']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if word.isdigit():\n",
    "                        lld[page][tb]['checks'].append(word)\n",
    "            if 'rates' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['rates']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if '.' in word:\n",
    "                        lld[page][tb]['rates'].append(float(word))\n",
    "            if 'positions' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['positions']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if len(word)>1:\n",
    "                        lld[page][tb]['positions'].append(word)\n",
    "            if 'fund' in nn[page][tb].keys():\n",
    "                lld[page][tb]['fund'] = nn[page][tb]['fund']\n",
    "            if 'acct' in nn[page][tb].keys():\n",
    "                lld[page][tb]['acct'] = nn[page][tb]['acct']\n",
    "            if 'obj' in nn[page][tb].keys():\n",
    "                lld[page][tb]['obj'] = nn[page][tb]['obj']\n",
    "            if 'earnings' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['earnings']\n",
    "                had_underscore = False\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if '.' in word:\n",
    "                        if not had_underscore: \n",
    "                            lld[page][tb]['earnings'].append(float(word))\n",
    "                            had_underscore = False\n",
    "                    elif '_' in word:\n",
    "                        had_underscore = True\n",
    "            if (len(lld[page][tb]['checks']) < len(lld[page][tb]['dates'])):\n",
    "                new_checks = []\n",
    "                check_index = 0\n",
    "                for i in np.arange(len(lld[page][tb]['earnings'])):\n",
    "                    if (lld[page][tb]['earnings'][i] > 0.0):\n",
    "                        new_checks.append(lld[page][tb]['checks'][check_index])\n",
    "                        check_index += 1\n",
    "                    else:\n",
    "                        new_checks.append('gen'+str(page) + '-' + str(tb) + '-' + str(i))\n",
    "                        print(\"inserting check number: \",page,tb,i)\n",
    "                lld[page][tb]['checks'] = new_checks\n",
    "    return(lld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the earnings reports and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting check number:  262 6 39\n",
      "inserting check number:  262 6 40\n",
      "inserting check number:  43 6 30\n",
      "inserting check number:  51 6 49\n",
      "inserting check number:  94 7 19\n"
     ]
    }
   ],
   "source": [
    "def process_earnings(pdf):\n",
    "    nnd = get_names(pdf)\n",
    "    cnd = consolidate_name_boxes(nnd)\n",
    "    newnames = combdd(cnd,pdf)\n",
    "    lld = get_lines(newnames)\n",
    "    return(lld)\n",
    "\n",
    "ll={}\n",
    "\n",
    "ll[2017] = process_earnings(p17)\n",
    "ll[2018] = process_earnings(p18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check earnings against totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22608024.34\n",
      "22409915.41\n"
     ]
    }
   ],
   "source": [
    "totearn = {}\n",
    "\n",
    "for year in ll.keys():\n",
    "    if year not in totearn.keys():\n",
    "        totearn[year] = 0.0\n",
    "    for page in ll[year].keys():\n",
    "        for tb in ll[year][page].keys():\n",
    "            for amt in ll[year][page][tb]['earnings']:\n",
    "                totearn[year] += amt\n",
    "                \n",
    "print(round(totearn[2017],2))       #FY2017 earnings report total is $22,608,024.34\n",
    "print(round(totearn[2018],2))       #FY2018 earnings report total is $22,409,915.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class check():                                                          #generic check class\n",
    "    def __init__(self,check_number,name,check_date):         #constructor\n",
    "        self.check_number   = check_number\n",
    "        self.name           = name\n",
    "        self.check_date     = check_date\n",
    "        self.items          = []\n",
    "        return\n",
    "\n",
    "    def get_name(self):\n",
    "        return(self.name)\n",
    "        \n",
    "    def get_date(self):\n",
    "        return(self.check_date)\n",
    "    \n",
    "    def get_fiscal_year(self):\n",
    "        y = self.check_date.year\n",
    "        m = self.check_date.month\n",
    "        if (m <= 6):\n",
    "            return(y)\n",
    "        else:\n",
    "            return(y+1)\n",
    "    \n",
    "    def get_items(self):\n",
    "        return(self.items)\n",
    "    \n",
    "    def add_item(self,fund,acct,obj,position,rate,earnings):\n",
    "        self.items.append({'fund':fund,'acct':acct,'obj':obj,'position':position,'rate':rate,'earnings':earnings})\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class payperiod():                                      #class for dates at end of payperiods\n",
    "    \"\"\"Provides a dictionary of payroll periods\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.payperiods = {}                            #initialize payperiods dictionary\n",
    "\n",
    "        delta = timedelta(days=14)                      #14 days per pay period\n",
    "        first_payperiod = date(2009,7,3)                #first pay period of FY2010\n",
    "        cutoff_date = date(2026,7,1)\n",
    "        \n",
    "        current_payperiod = first_payperiod\n",
    "        current_year = first_payperiod.year\n",
    "        current_month = first_payperiod.month\n",
    "\n",
    "        while (current_payperiod < cutoff_date):         #generate pay periods through cutoff date\n",
    "            self.payperiods[current_payperiod] = {}     #create empty dictionary for this payperiod\n",
    "            fyear = current_payperiod.year              #compute fiscal year\n",
    "            if (current_payperiod.month >= 7):          #for months7-12 it's current year plus 1\n",
    "               fyear += 1\n",
    "            self.payperiods[current_payperiod]['fyear'] = fyear\n",
    "            schyear = current_payperiod.year\n",
    "            if (current_payperiod.month < 8):\n",
    "               schyear = str(current_payperiod.year-1) + '-' + str(current_payperiod.year)\n",
    "            elif (current_payperiod.month > 8):\n",
    "               schyear = str(current_payperiod.year) + '-' + str(current_payperiod.year+1)\n",
    "            elif (current_payperiod.day < 14):\n",
    "               schyear = str(current_payperiod.year-1) + '-' + str(current_payperiod.year)\n",
    "            else:\n",
    "               schyear = str(current_payperiod.year) + '-' + str(current_payperiod.year+1)\n",
    "            self.payperiods[current_payperiod]['school_year'] = schyear\n",
    "            self.payperiods[current_payperiod]['calendar_year'] = current_payperiod.year\n",
    "            if ((current_payperiod.month == 6) & \\\n",
    "                ((current_payperiod+delta).month==7) & \\\n",
    "                ((current_payperiod+delta).day > 1)):\n",
    "                self.payperiods[current_payperiod]['spans_fyear'] = 'True'\n",
    "            else:\n",
    "                self.payperiods[current_payperiod]['spans_fyear'] = 'False'\n",
    "            current_payperiod += delta                                  #increment date by 14 days\n",
    "        \n",
    "        self.payperiods[date(2016,11,10)] = self.payperiods.pop(date(2016,11,11))\n",
    "        return\n",
    "    \n",
    "    def get_payperiods(self):\n",
    "        return(self.payperiods)\n",
    "    \n",
    "    def get_payperiod_end(self,fyear,ppno):                              #look up the date of the nth pay period\n",
    "        \"\"\"Lookup end date of payroll periods in a given fiscal year\"\"\"\n",
    "        try:\n",
    "            ppend = self.payperiods[fyear][ppno]\n",
    "        except KeyError:\n",
    "            ppend = np.NaN\n",
    "            \n",
    "        return(ppend)    \n",
    "        \n",
    "    def get_fiscal_year(self,xdate):                    #look up the fiscal year given a date\n",
    "        \"\"\"Lookup fiscal year given date\"\"\"\n",
    "        fyr = xdate.year\n",
    "        mon = xdate.month\n",
    "        if (mon > 6):\n",
    "            fyr += 1\n",
    "        return(fyr)\n",
    "    \n",
    "    def get_school_year(self,xdate):                    #look up the fiscal year given a date\n",
    "        \"\"\"Lookup school year given date\"\"\"\n",
    "        return(self.payperiods[xdate]['school_year'])\n",
    "    \n",
    "    def get_payperiod_no(self,fyear,xdate):             #look up the pay period number for a date\n",
    "        \"\"\"Lookup payroll period given a date\"\"\"\n",
    "        period=1\n",
    "        while self.payperiods[fyear][period] >= xdate:\n",
    "            period += 1\n",
    "        return(period)\n",
    "    \n",
    "    def get_next_payday(self,y,m,d):                                    #find the next payday after given date\n",
    "        \"\"\"Find the end of the current pay period given a date\"\"\"\n",
    "        d = date(y,m,d)                                                 #convert y,m,d to date value\n",
    "    \n",
    "        for pdate in self.payperiods.keys():                            #look through paydates\n",
    "            if (payday >= d):                                       #return the first one greater than \n",
    "                return(payday)                                      #the date supplied\n",
    "            \n",
    "        return(np.NaN)\n",
    "    \n",
    "    def get_previous_payday(self,cdate):                            #find the previous payday\n",
    "        \"\"\"Find the date of the previous payday\"\"\"\n",
    "        \n",
    "        tdate = np.NaN\n",
    "        \n",
    "        for pdate in sorted(self.payperiods.keys()):                #look through paydates\n",
    "            if (pdate <= cdate):                                    #return the last one less than or equal\n",
    "                tdate = pdate\n",
    "            \n",
    "        return(tdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_payperiod_end(fyear,ppno):  Lookup end date of payroll periods in a given fiscal year\n"
     ]
    }
   ],
   "source": [
    "pp = payperiod()          #get end dates of payroll periods\n",
    "print('get_payperiod_end(fyear,ppno): ',pp.get_payperiod_end.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjusting date HARE, KIMBERLY C 2016-10-06 2016-09-30\n",
      "adjusting date MALLILO, NATALIE A 2016-10-18 2016-10-14\n",
      "adjusting date MALLILO, NATALIE A 2016-10-18 2016-10-14\n",
      "adjusting date HARE, KIMBERLY C 2016-10-06 2016-09-30\n",
      "adjusting date GARDINER, PATRICIA S 2018-05-02 2018-04-27\n"
     ]
    }
   ],
   "source": [
    "checks = {}\n",
    "\n",
    "pp = payperiod()          #get end dates of payroll periods\n",
    "\n",
    "paydays = pp.get_payperiods()\n",
    "\n",
    "for year in ll.keys():\n",
    "    for page in ll[year].keys():\n",
    "        for tb in ll[year][page].keys():\n",
    "            check_numbers = ll[year][page][tb]['checks']\n",
    "            names         = ll[year][page][tb]['names']\n",
    "            check_dates   = ll[year][page][tb]['dates']\n",
    "            fund          = ll[year][page][tb]['fund']\n",
    "            acct          = ll[year][page][tb]['acct']\n",
    "            obj           = ll[year][page][tb]['obj']\n",
    "            positions     = ll[year][page][tb]['positions']\n",
    "            rates         = ll[year][page][tb]['rates']\n",
    "            earnings      = ll[year][page][tb]['earnings']\n",
    "            \n",
    "            for i in np.arange(len(check_numbers)):\n",
    "                check_number = check_numbers[i]\n",
    "                name         = names[i]\n",
    "                date_str     = check_dates[i]\n",
    "                words = date_str.split('/')\n",
    "                check_date   = date(int(words[2]),int(words[0]),int(words[1]))\n",
    "                if (check_date not in paydays.keys()):\n",
    "                    new_date = pp.get_previous_payday(check_date)\n",
    "                    print('adjusting date',name,check_date,new_date)\n",
    "                    check_date = new_date\n",
    "                if check_number not in checks.keys():\n",
    "                    checks[check_number] = check(check_number,name,check_date)\n",
    "                position = positions[i]\n",
    "                rate     = rates[i]\n",
    "                earned   = earnings[i]\n",
    "                checks[check_number].add_item(fund,acct,obj,position,rate,earned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-08 712582.64\n",
      "2016-07-22 731432.74\n",
      "2016-08-05 727235.05\n",
      "2016-08-19 830534.38\n",
      "2016-09-02 873373.4\n",
      "2016-09-16 851594.36\n",
      "2016-09-30 894158.83\n",
      "2016-10-14 909581.63\n",
      "2016-10-28 872404.3\n",
      "2016-11-10 873875.89\n",
      "2016-11-25 867629.52\n",
      "2016-12-09 927504.0\n",
      "2016-12-23 876349.06\n",
      "2017-01-06 1072459.77\n",
      "2017-01-20 880519.3\n",
      "2017-02-03 877020.3\n",
      "2017-02-17 874339.35\n",
      "2017-03-03 868450.13\n",
      "2017-03-17 881158.86\n",
      "2017-03-31 881394.06\n",
      "2017-04-14 890815.44\n",
      "2017-04-28 861520.55\n",
      "2017-05-12 969064.7\n",
      "2017-05-26 899585.29\n",
      "2017-06-09 814842.99\n",
      "2017-06-23 888597.8\n",
      "2017-07-07 789836.2\n",
      "2017-07-21 752795.33\n",
      "2017-08-04 755545.28\n",
      "2017-08-18 878423.53\n",
      "2017-09-01 857147.41\n",
      "2017-09-15 868564.35\n",
      "2017-09-29 857886.53\n",
      "2017-10-13 916538.88\n",
      "2017-10-27 879381.42\n",
      "2017-11-10 876286.0\n",
      "2017-11-24 875194.05\n",
      "2017-12-08 918455.79\n",
      "2017-12-22 886606.47\n",
      "2018-01-05 857416.1\n",
      "2018-01-19 918743.59\n",
      "2018-02-02 900223.44\n",
      "2018-02-16 875292.52\n",
      "2018-03-02 852273.64\n",
      "2018-03-16 874380.51\n",
      "2018-03-30 873770.06\n",
      "2018-04-13 873510.17\n",
      "2018-04-27 863265.62\n",
      "2018-05-11 953343.14\n",
      "2018-05-25 885823.46\n",
      "2018-06-08 782210.99\n",
      "2018-06-22 787000.93\n"
     ]
    }
   ],
   "source": [
    "earns = {}\n",
    "\n",
    "for check in checks.keys():\n",
    "    check_date = checks[check].get_date()\n",
    "    if check_date not in earns.keys():\n",
    "        earns[check_date] = 0.0\n",
    "    itms = checks[check].get_items()\n",
    "    for item in itms:\n",
    "        earns[check_date] += item['earnings']\n",
    "    \n",
    "for ckdate in sorted(earns.keys()):\n",
    "    print(ckdate,round(earns[ckdate],2))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
