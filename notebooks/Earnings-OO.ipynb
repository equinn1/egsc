{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read earnings reports (OO version)\n",
    "\n",
    "E. Quinn 12/22/2019\n",
    "\n",
    "This notebook uses pdfminer to extract the information from the individual earnings report\n",
    "\n",
    "The documentation for pdfminer is at:\n",
    "\n",
    "https://buildmedia.readthedocs.org/media/pdf/pdfminer-docs/latest/pdfminer-docs.pdf\n",
    "\n",
    "Maintenance:\n",
    "\n",
    "* 3/6/2020  \n",
    "  * Add check date and number\n",
    "* 3/7/2020  \n",
    "  * Align personnel classes with support professionals structure\n",
    "  * Implement salary step capture for support professionals\n",
    "* 4/8/2020\n",
    "  * Rewrite logic to base data structure on check number and check date\n",
    "  * Simplify payment decoding logic to take advantage of having check date\n",
    "  * Data corrections for check dates and numbers:\n",
    "    * Adjust 5 check dates to aliign with nearest payday\n",
    "    * Generate 4 artificial check numbers for zero earnings lines\n",
    "    \n",
    "To do:\n",
    "* Replace computed salary matrix for FY2020 with numbers from contract (correct small rounding errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import standard python datascience packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "from datascience import *\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pdfminer packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LTTextBoxHorizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the directory we are running in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EG accounting codes class\n",
    "\n",
    "provides descriptions for EG accounting codes and mapping to UCOA codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EG_acct_codes():\n",
    "    def __init__(self):\n",
    "        self.EG_account_codes ={\n",
    "            '71100105': 'K Frenchtown',\n",
    "            '71100107': 'K MDBK',\n",
    "            '71109105': 'Title 1  Frenchtown',\n",
    "            '71109107': 'Title 1  MDBK',\n",
    "            '71110105': 'Grade 1 Frenchtown',\n",
    "            '71110107': 'Grade 1 MDBK',\n",
    "            '71120105': 'Grade 2 Frenchtown',\n",
    "            '71120107': 'Grade 2 MDBK',\n",
    "            '71121102': 'Art Eldredge',\n",
    "            '71121103': 'Art Cole',\n",
    "            '71121105': 'Art Frenchtown',\n",
    "            '71121106': 'Art EGHS',\n",
    "            '71121107': 'Art MDBK',\n",
    "            '71121108': 'Art Hanaford',\n",
    "            '71123103': 'ELA Cole',\n",
    "            '71123106': 'ELA EGHS',\n",
    "            '71123108': 'ELA Hanaford',\n",
    "            '71124103': 'Foreign Language Cole',\n",
    "            '71124106': 'Foreign Language EGHS',\n",
    "            '71125102': 'PE/health Eldredge',\n",
    "            '71125103': 'PE/health Cole',\n",
    "            '71125105': 'PE/health Frenchtown',\n",
    "            '71125106': 'PE/health EGHS',\n",
    "            '71125107': 'PE/health MDBK',\n",
    "            '71125108': 'PE/health Hanaford',\n",
    "            '71126103': 'Tech Cole',\n",
    "            '71126306': 'Tech EGHS',\n",
    "            '71127103': 'Math Cole',\n",
    "            '71127106': 'Math EGHS',\n",
    "            '71128102': 'Music Eldredge',\n",
    "            '71128103': 'Music Cole',\n",
    "            '71128105': 'Music Frenchtown',\n",
    "            '71128106': 'Music EGHS',\n",
    "            '71128107': 'Music MDBK',\n",
    "            '71128108': 'Music Hanaford',\n",
    "            '71129103': 'Science Cole',\n",
    "            '71129106': 'Science EGHS',\n",
    "            '71130102': 'Grade 3 Eldredge',\n",
    "            '71130105': 'Grade 3 Frenchtown',\n",
    "            '71130108': 'Grade 3 Hanaford',\n",
    "            '71130406': 'Business/Computer  EGHS',\n",
    "            '71131103': 'Social Studies Cole',\n",
    "            '71131106': 'Social Studies EGHS',\n",
    "            '71140102': 'Grade 4 Eldredge',\n",
    "            '71140108': 'Grade 4 Hanaford',\n",
    "            '71140403': 'Computer Cole',\n",
    "            '71140406': 'Computer EGHS',\n",
    "            '71141102': 'Reading Eldredge',\n",
    "            '71141103': 'Reading Cole',\n",
    "            '71141105': 'Reading Frenchtown',\n",
    "            '71141106': 'Reading EGHS',\n",
    "            '71141107': 'Reading MDBK',\n",
    "            '71141108': 'Reading Hanaford',\n",
    "            '71150102': 'Grade 5 Eldredge',\n",
    "            '71150108': 'Grade 5 Hanaford',\n",
    "            '71180102': 'SPED Eldredge',\n",
    "            '71180103': 'SPED EGHS',\n",
    "            '71180105': 'SPED Frenchtown',\n",
    "            '71180106': 'SPED EGHS',\n",
    "            '71180107': 'SPED MDBK',\n",
    "            '71180108': 'SPED Hanaford',\n",
    "            '71181102': 'SPED Life Skills Eldredge',\n",
    "            '71181103': 'SPED Life Skills Cole',\n",
    "            '71181105': 'SPED Life Skills Frenchtown',\n",
    "            '71181106': 'SPED Life Skills EGHS',\n",
    "            '71181107': 'SPED Life Skills MDBK',\n",
    "            '71182107': 'SPED EGHS',\n",
    "            '71191302': 'ESL Eldredge',\n",
    "            '71191303': 'ESL Cole',\n",
    "            '71191305': 'ESL Frenchtown',\n",
    "            '71191306': 'ESL EGHS',\n",
    "            '71191307': 'ESL MDBK',\n",
    "            '71191308': 'ESL Hanaford',\n",
    "            '71210202': 'Teacher Subs Eldredge',\n",
    "            '71210203': 'Teacher Subs Cole',\n",
    "            '71210205': 'Teacher Subs Frenchtown',\n",
    "            '71210206': 'Teacher Subs EGHS',\n",
    "            '71210207': 'Teacher Subs MDBK',\n",
    "            '71210208': 'Teacher Subs Hanaford',\n",
    "            '71210402': 'Long Term Subs Eldredge',\n",
    "            '71210403': 'Long Term Subs Cole',\n",
    "            '71210405': 'Long Term Subs Frenchtown',\n",
    "            '71210406': 'Long Term Subs EGHS',\n",
    "            '71210407': 'Long Term Subs MDBK',\n",
    "            '71210408': 'Long Term Subs Hanaford',\n",
    "            '71223102': 'Para Subs Eldredge',\n",
    "            '71223103': 'Para Subs Cole',\n",
    "            '71223105': 'Para Subs Frenchtown',\n",
    "            '71223106': 'Para Subs EGHS',\n",
    "            '71223107': 'Para Subs MDBK',\n",
    "            '71223108': 'Para Subs Hanaford',\n",
    "            '71231503': 'Guidance Cole',\n",
    "            '71231506': 'Guidance EGHS',\n",
    "            '71246702': 'Librarian Eldredge',\n",
    "            '71246703': 'Librarian Cole',\n",
    "            '71246705': 'Librarian Frenchtown',\n",
    "            '71246706': 'Librarian EGHS',\n",
    "            '71246707': 'Librarian MDBK',\n",
    "            '71246708': 'Librarian Hanaford',\n",
    "            '71269506': 'Nurse EGHS',\n",
    "            '71270102': 'Nurse Subs Eldredge',\n",
    "            '71270103': 'Nurse Subs Cole',\n",
    "            '71270105': 'Nurse Subs Frenchtown',\n",
    "            '71270106': 'Nurse Subs EGHS',\n",
    "            '71270107': 'Nurse Subs MDBK',\n",
    "            '71270108': 'Nurse Subs Hanaford',\n",
    "            '71270302': 'Nurse Eldredge',\n",
    "            '71270303': 'Nurse Cole',\n",
    "            '71270305': 'Nurse Frenchtown',\n",
    "            '71270306': 'Nurse EGHS',\n",
    "            '71270307': 'Nurse MDBK',\n",
    "            '71270308': 'Nurse Hanaford',\n",
    "            '71301106': 'SPED EGHS',\n",
    "            '71301602': 'Social Worker Eldredge',\n",
    "            '71301603': 'Social Worker Cole',\n",
    "            '71301605': 'Social Worker Frenchtown',\n",
    "            '71301606': 'Social Worker EGHS',\n",
    "            '71301607': 'Social Worker MDBK',\n",
    "            '71301608': 'Social Worker Hanaford',\n",
    "            '71302702': 'OT Eldredge',\n",
    "            '71302703': 'OT Cole',\n",
    "            '71302705': 'OT Frenchtown',\n",
    "            '71302706': 'OT EGHS',\n",
    "            '71302707': 'OT MDBK',\n",
    "            '71302708': 'OT Hanaford',\n",
    "            '71308102': 'Adaptive PE Eldredge',\n",
    "            '71308103': 'Adaptive PE Cole',\n",
    "            '71308105': 'Adaptive PE Frenchtown',\n",
    "            '71308106': 'Adaptive PE EGHS',\n",
    "            '71308107': 'Adaptive PE MDBK',\n",
    "            '71308108': 'Adaptive PE Hanaford',\n",
    "            '71310106': 'History EGHS',\n",
    "            '71311702': 'Psychologist Eldredge',\n",
    "            '71311703': 'Psychologist Cole',\n",
    "            '71311705': 'Psychologist Frenchtown',\n",
    "            '71311706': 'Psychologist EGHS',\n",
    "            '71311707': 'Psycholotist MDBK',\n",
    "            '71311708': 'Psychologist Hanaford',\n",
    "            '71321802': 'Speech Eldredge',\n",
    "            '71321803': 'Speech Cole',\n",
    "            '71321805': 'Speech Frenchtown',\n",
    "            '71321806': 'Speech EGHS',\n",
    "            '71321807': 'Speech MDBK',\n",
    "            '71321808': 'Speech Hanaford',\n",
    "            '71347302': 'Custodian Subs Eldredge',\n",
    "            '71347303': 'Custodian Subs Cole',\n",
    "            '71347305': 'Custodian Subs Frenchtown',\n",
    "            '71347306': 'Custodian Subs EGHS',\n",
    "            '71347307': 'Custodian Subs MDBK',\n",
    "            '71347308': 'Custodian Subs Hanaford'\n",
    "        }\n",
    "        self.local_to_ucoa = {\n",
    "            '711001': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1,'JC':1100,'Sub Desc':'K'},\n",
    "            '711101': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 3,'JC':1100, 'Sub Desc': 'Grade 1'},\n",
    "            '711201': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 4,'JC':1100, 'Sub Desc': 'Grade 2'},\n",
    "            '711301': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 5,'JC':1100, 'Sub Desc': 'Grade 3'},\n",
    "            '711401': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 6,'JC':1100, 'Sub Desc': 'Grade 4'},\n",
    "            '711501': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 7,'JC':1100, 'Sub Desc': 'Grade 5'},\n",
    "            '711211': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 200,'JC':1100, 'Sub Desc': 'Art'},\n",
    "            '711231': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 500,'JC':1100, 'Sub Desc': 'ELA'},\n",
    "            '711241': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 700,'JC':1100, 'Sub Desc': 'Foreign Language'},\n",
    "            '711251': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1200,'JC':1100, 'Sub Desc': 'PE/health'},\n",
    "            '711271': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1500,'JC':1100, 'Sub Desc': 'Math'},\n",
    "            '711281': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1600,'JC':1100, 'Sub Desc': 'Music'},\n",
    "            '711291': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1700,'JC':1100, 'Sub Desc': 'Science'},\n",
    "            '711311': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1900,'JC':1100, 'Sub Desc': 'Social Studies'},\n",
    "            '711411': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 2400,'JC':1100, 'Sub Desc': 'Reading'},\n",
    "            '711261': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 2000,'JC':1100, 'Sub Desc': 'Tech/computer'},\n",
    "            '711404': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 2000,'JC':1100, 'Sub Desc': 'Tech/computer'},\n",
    "            '712467': {'Fund':1000000,'Prog':10,'Func':212,'Sub': 2600,'JC':1600, 'Sub Desc': 'Librarian'},\n",
    "            '713027': {'Fund':1000000,'Prog':20,'Func':232,'Sub': 2125,'JC':1700, 'Sub Desc': 'Occupational Therapy'},\n",
    "            '713218': {'Fund':1000000,'Prog':20,'Func':232,'Sub': 2122,'JC':1700, 'Sub Desc': 'Speech Therapy'},\n",
    "            '713117': {'Fund':1000000,'Prog':20,'Func':232,'Sub': 2121,'JC':1700, 'Sub Desc': 'Psychologist'},\n",
    "            '713016': {'Fund':1000000,'Prog':20,'Func':232,'Sub': 2120,'JC':1700, 'Sub Desc': 'Social Worker'},\n",
    "            '719130': {'Fund':1000000,'Prog':40,'Func':111,'Sub': 600,'JC':1300, 'Sub Desc': 'ESL'},\n",
    "            '711304': {'Fund':1000000,'Prog':10,'Func':111,'Sub': 1800,'JC':1100, 'Sub Desc': 'Business/comp'},\n",
    "            '712315': {'Fund':1000000,'Prog':10,'Func':211,'Sub': 800,'JC':1500, 'Sub Desc': 'Guidance'}\n",
    "        }\n",
    "        return\n",
    "        \n",
    "    def get_eg_acct_desc(self,acct):\n",
    "        \"\"\"Provides descriptions for accounting codes in EG MUNIS system.\"\"\"\n",
    "        try:\n",
    "            return(self.EG_account_codes[acct])\n",
    "        except KeyError:\n",
    "            return('(no description)')\n",
    "        \n",
    "    def get_eg_acct_UCOA(self,acct):\n",
    "        \"\"\"Provides UCOA codes for accounting codes in EG MUNIS system.\"\"\"\n",
    "        try:\n",
    "            return(self.local_to_ucoa[acct])\n",
    "        except KeyError:\n",
    "            return({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RIDE Object labels class\n",
    "\n",
    "provides a lookup table for RIDE UCOA Object Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIDE_Obj_labels():\n",
    "    \"\"\"Provides a dictionary of RIDE Obj descriptions\"\"\"\n",
    "    \n",
    "    def __init__(self):                                        #download RIDE UCOA data and extract Obj codes\n",
    "            \n",
    "        self.obj_labels = {}\n",
    "\n",
    "        fydf = pd.read_csv(\"../Obj.csv\") #read the file for this fiscal year\n",
    "        \n",
    "        objdd = fydf.to_dict()\n",
    "\n",
    "        for key in objdd['obj'].keys():\n",
    "            obj = int(str(objdd['obj'][key]))\n",
    "            self.obj_labels[obj] = objdd['obj_desc'][key]\n",
    "            \n",
    "    def get_obj_desc(self,obj):                                            #look up RIDE Obj description\n",
    "        \"\"\"Provides a lookup function for Obj description\"\"\"\n",
    "        try:\n",
    "            obj_desc = self.obj_labels[obj]                                #return description if found\n",
    "        except KeyError:\n",
    "            obj_desc = '(none)'                                            #otherwise return '(none)'\n",
    "                \n",
    "        return(obj_desc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pay_check class\n",
    "\n",
    "Represents a line in the earnings report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pay_check():                                                            #generic check class\n",
    "    def __init__(self,check_number,name,check_date,payperiod_object):         #constructor\n",
    "        self.check_number   = check_number\n",
    "        self.name           = name\n",
    "        self.check_date     = check_date\n",
    "        self.items          = {}\n",
    "        self.pay_period     = payperiod_object\n",
    "        self.fiscal_year    = self.pay_period.get_fiscal_year(check_date)\n",
    "        self.school_year    = self.pay_period.get_school_year(check_date)\n",
    "        self.calendar_year  = check_date.year\n",
    "        return\n",
    "\n",
    "    def get_name(self):\n",
    "        return(self.name)\n",
    "        \n",
    "    def get_date(self):\n",
    "        return(self.check_date)\n",
    "    \n",
    "    def get_number(self):\n",
    "        return(self.check_number)\n",
    "    \n",
    "    def get_fiscal_year(self):\n",
    "        return(self.fiscal_year)\n",
    "\n",
    "    def get_school_year(self):\n",
    "        return(self.school_year)\n",
    "\n",
    "    def get_calendar_year(self):\n",
    "        return(self.calendar_year)\n",
    "    \n",
    "    def get_items(self):\n",
    "        return(self.items)\n",
    "    \n",
    "    def add_item(self,fund,acct,obj,position,rate,earnings,acct_desc,obj_desc,acct_UCOA,stepinfo):\n",
    "        item_number = len(self.items) + 1\n",
    "        self.items[item_number] = {'fund':fund,'acct':acct,'obj':obj,'position':position, \\\n",
    "            'rate':rate,'earnings':earnings,'acct_desc':acct_desc,'obj_desc':obj_desc, \\\n",
    "            'acct_UCOA':acct_UCOA,'step_info':stepinfo}\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payperiod class\n",
    "\n",
    "Represents a two-week pay period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class payperiod():                                      #class for dates at end of payperiods\n",
    "    \"\"\"Provides a dictionary of payroll periods\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.payperiods = {}                            #initialize payperiods dictionary\n",
    "\n",
    "        delta = timedelta(days=14)                      #14 days per pay period\n",
    "        first_payperiod = date(2009,7,3)                #first pay period of FY2010\n",
    "        cutoff_date = date(2026,7,1)\n",
    "        \n",
    "        current_payperiod = first_payperiod\n",
    "        current_year = first_payperiod.year\n",
    "        current_month = first_payperiod.month\n",
    "\n",
    "        while (current_payperiod < cutoff_date):         #generate pay periods through cutoff date\n",
    "            self.payperiods[current_payperiod] = {}     #create empty dictionary for this payperiod\n",
    "            fyear = current_payperiod.year              #compute fiscal year\n",
    "            if (current_payperiod.month >= 7):          #for months7-12 it's current year plus 1\n",
    "               fyear += 1\n",
    "            self.payperiods[current_payperiod]['fyear'] = fyear\n",
    "            schyear = current_payperiod.year\n",
    "            if (current_payperiod.month < 8):\n",
    "               schyear = str(current_payperiod.year-1) + '-' + str(current_payperiod.year)\n",
    "            elif (current_payperiod.month > 8):\n",
    "               schyear = str(current_payperiod.year) + '-' + str(current_payperiod.year+1)\n",
    "            elif (current_payperiod.day < 14):\n",
    "               schyear = str(current_payperiod.year-1) + '-' + str(current_payperiod.year)\n",
    "            else:\n",
    "               schyear = str(current_payperiod.year) + '-' + str(current_payperiod.year+1)\n",
    "            self.payperiods[current_payperiod]['school_year'] = schyear\n",
    "            self.payperiods[current_payperiod]['calendar_year'] = current_payperiod.year\n",
    "            if ((current_payperiod.month == 6) & \\\n",
    "                ((current_payperiod+delta).month==7) & \\\n",
    "                ((current_payperiod+delta).day > 1)):\n",
    "                self.payperiods[current_payperiod]['spans_fyear'] = 'True'\n",
    "            else:\n",
    "                self.payperiods[current_payperiod]['spans_fyear'] = 'False'\n",
    "            current_payperiod += delta                                  #increment date by 14 days\n",
    "        \n",
    "        self.payperiods[date(2016,11,10)] = self.payperiods.pop(date(2016,11,11))\n",
    "        return\n",
    "    \n",
    "    def get_payperiods(self):\n",
    "        return(self.payperiods)\n",
    "    \n",
    "    def get_payperiod_end(self,fyear,ppno):                              #look up the date of the nth pay period\n",
    "        \"\"\"Lookup end date of payroll periods in a given fiscal year\"\"\"\n",
    "        try:\n",
    "            ppend = self.payperiods[fyear][ppno]\n",
    "        except KeyError:\n",
    "            ppend = np.NaN\n",
    "            \n",
    "        return(ppend)    \n",
    "        \n",
    "    def get_fiscal_year(self,xdate):                    #look up the fiscal year given a date\n",
    "        \"\"\"Lookup fiscal year given date\"\"\"\n",
    "        fyr = xdate.year\n",
    "        mon = xdate.month\n",
    "        if (mon > 6):\n",
    "            fyr += 1\n",
    "        return(fyr)\n",
    "    \n",
    "    def get_school_year(self,xdate):                    #look up the fiscal year given a date\n",
    "        \"\"\"Lookup school year given date\"\"\"\n",
    "        return(self.payperiods[xdate]['school_year'])\n",
    "    \n",
    "    def get_payperiod_no(self,fyear,xdate):             #look up the pay period number for a date\n",
    "        \"\"\"Lookup payroll period given a date\"\"\"\n",
    "        period=1\n",
    "        while self.payperiods[fyear][period] >= xdate:\n",
    "            period += 1\n",
    "        return(period)\n",
    "    \n",
    "    def get_next_payday(self,y,m,d):                                    #find the next payday after given date\n",
    "        \"\"\"Find the end of the current pay period given a date\"\"\"\n",
    "        d = date(y,m,d)                                                 #convert y,m,d to date value\n",
    "    \n",
    "        for pdate in self.payperiods.keys():                            #look through paydates\n",
    "            if (payday >= d):                                       #return the first one greater than \n",
    "                return(payday)                                      #the date supplied\n",
    "            \n",
    "        return(np.NaN)\n",
    "    \n",
    "    def get_previous_payday(self,cdate):                            #find the previous payday\n",
    "        \"\"\"Find the date of the previous payday\"\"\"\n",
    "        \n",
    "        tdate = np.NaN\n",
    "        \n",
    "        for pdate in sorted(self.payperiods.keys()):                #look through paydates\n",
    "            if (pdate <= cdate):                                    #return the last one less than or equal\n",
    "                tdate = pdate\n",
    "            \n",
    "        return(tdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class teacher_salary_matrix():\n",
    "    def __init__(self):                                       #constructor\n",
    "\n",
    "        self.cba_cols ={'B': 0,'B+30': 1,'M': 2,'M+30': 3,'M2/CAGS': 4, 'D': 5}\n",
    "        \n",
    "        self.cba = np.zeros((10, 10, 6))    #salary matrix is 3-D numpy array indexed by: fyear, step, column\n",
    "        \n",
    "                                                                #start with FY2016 (2015-2016) salary matrix\n",
    "        self.cba[3,:,:] = np.array([\n",
    "            [41286, 42900, 43871, 44505, 44893, 45186],\n",
    "            [44871, 46484, 47454, 48085, 48474, 48771],\n",
    "            [48494, 50106, 51078, 51709, 52098, 52393],\n",
    "            [52118, 53729, 54700, 55332, 55722, 56018],\n",
    "            [55743, 57354, 58328, 58958, 59347, 59642],\n",
    "            [59366, 60979, 61951, 62583, 62974, 63266],\n",
    "            [62991, 64605, 65574, 66206, 66596, 66892],\n",
    "            [66616, 68228, 69199, 69829, 69806, 70515],\n",
    "            [71741, 73353, 74323, 74954, 75345, 75639],\n",
    "            [78898, 80675, 81743, 82438, 82866, 83190]]) \n",
    "        \n",
    "                                                                #FY2017 (2016-2017) is the same as FY2016\n",
    "        self.cba[4,:,:] = self.cba[3,:,:]\n",
    "        \n",
    "                                                                #FY2018 (2017-2018) 2% increase\n",
    "        self.cba[5,:,:] = np.around(1.02*self.cba[4,:,:],0)\n",
    "        \n",
    "                                                                #FY2019 (2018-2019) 2.25% increase\n",
    "        self.cba[6,:,:] = np.around(1.0225*self.cba[5,:,:],0)\n",
    "        \n",
    "                                                                #FY2020 (2019-2020) same as FY2019\n",
    "        self.cba[7,:,:] = self.cba[6,:,:]\n",
    "        \n",
    "                                                                #FY2021 (2020-2021) 2% increase\n",
    "        self.cba[8,:,:] = np.around(1.02*self.cba[7,:,:],0)\n",
    "        \n",
    "                                                                #FY2022 (2021-2022) 2.25% increase\n",
    "        self.cba[9,:,:] = np.around(1.0225*self.cba[8,:,:],0)\n",
    "\n",
    "        \n",
    "                                                                #FY2015: back out 2% increase from FY2016\n",
    "        self.cba[2,:,:] = np.around(self.cba[3,:,:]/1.02,0) \n",
    "        \n",
    "                                                                #FY2014: back out 2.5% increase from FY2015\n",
    "        self.cba[1,:,:] = np.around(self.cba[2,:,:]/1.025,0)  \n",
    "        \n",
    "                                                                #FY2013: back out 1.01% from FY2014 for steps 1-9\n",
    "        self.cba[0,0:8,:] = np.around(self.cba[1,0:8,:]/1.01,0)\n",
    "                                                                #FY2013: back out 2.25% from FY2014 for step 10\n",
    "        self.cba[0,9,:]   = np.around(self.cba[1,9,:]/1.0225,0)  \n",
    "        return            \n",
    "    \n",
    "    def get_cba_matrix(self):\n",
    "        return(self.cba)\n",
    "    \n",
    "    def get_salary(self,fyear,step,col):                        #look up salary by year, column, step\n",
    "        \"\"\"Returns CBA salary given fiscal year, column, and step for FY2013-FY2022.\"\"\"\n",
    "        yr = fyear - 2013                                       #year index 0 is 2013\n",
    "        s  = step-1                                             #step index is one less than the step number\n",
    "        c = col                                                 #column within the CBA salary matrix\n",
    "        \n",
    "        try:\n",
    "            return self.cba[yr,s,c]                             #return the value if it exists\n",
    "        except KeyError:                                        #otherwise raise error condition\n",
    "            print(\"KeyError in get_salary: \",yr,s,c)\n",
    "        except IndexError:\n",
    "            print(\"IndexError in get_salary: \",yr,s,c)\n",
    "    \n",
    "    def decode_earnings(self,check_date,rate,earnings,pp):  #compute step, FTE, # of payments for teachers\n",
    "        \n",
    "        dct = {}\n",
    "        \n",
    "        f = [1.0,1/2.,1/10.,1/5.,4/5.,3/10.,\\\n",
    "            4/10.,6/10.,1/20.,1/3.,2/3.,1/4.,\\\n",
    "            3/4.,1/5.,2/5.,3/5.,4/5.,1/6.,5/6.,\\\n",
    "            1/7.,2/7.,3/7.,4/7.,5/7.,6/7.,1/8.,\\\n",
    "            3/8.,5/8.,7/8.,1/9.,2/9.,4/9.,5/9.,\\\n",
    "             7/9.,8/9.,7/10.,9/10.]                    #possible FTE fractions\n",
    "        \n",
    "        cbacols ={'B': 0,'B+30': 1,'M': 2,\\\n",
    "                  'M+30': 3,'M2/CAGS': 4, 'D': 5}               #cba salary matrix columns\n",
    "\n",
    "        salary = round(184.0*rate,0)                            #salary is 184 times daily rate\n",
    "        lower_bound = salary - 1.0                              #lower limit for tolerance\n",
    "        upper_bound = salary + 1.0                              #upper limit for tolerance\n",
    "        step_code = ''                                          #initialize step code\n",
    "        n_payments = [26.0,21.0]                                #possible number of payments: 26 or 21                              \n",
    "        fte = np.NaN\n",
    "        payments = np.NaN\n",
    "        min_abs_diff = 10000. \n",
    "        \n",
    "        fyear = pp.get_fiscal_year(check_date)\n",
    "        school_year_string = pp.get_school_year(check_date)\n",
    "        sy = int(school_year_string[5:])               #\n",
    "                                                                #search salary matrix for a match\n",
    "        for step in np.arange(1,11):                        #loop through steps\n",
    "            for col in self.cba_cols.keys():                #loop through columns\n",
    "                cbasal = self.get_salary(sy,\\\n",
    "                    step,self.cba_cols[col])                #salary from CBA matrix\n",
    "                if( (lower_bound <= cbasal) &\\\n",
    "                    (cbasal <= upper_bound) ):               #computed salary within $1 of CBA\n",
    "                    step_code = str(sy) + '-' + col + '-' + str(step)    #code is:  yyyy-cat-step\n",
    "\n",
    "        if ((rate > 200.) | (earnings > 1000.)):       #determine fte and payments from rate\n",
    "            for p in n_payments:                                #loop through payments 26 and 21\n",
    "                for frac in f:                                  #loop through the FTE fractions in the list\n",
    "                    diff = abs(earnings - 184.0*rate*frac/p)    #compute the difference from earnings\n",
    "                    if (diff < min_abs_diff):                   #see if this is the smallest so far\n",
    "                        min_abs_diff = diff                     #if it is, then save the min difference\n",
    "                        payments = p                            #save the number of payments\n",
    "                        fte = frac                              #save the FTE fraction\n",
    "        elif ((rate > 0.0) & \\\n",
    "              (rate < 100.) & \\\n",
    "              (earnings > 500.)):                               #do this when rate is too low to be a daily rate\n",
    "            for p in n_payments:                                #loop through possible payments 26 and 21\n",
    "                for frac in f:                                  #loop through possible FTE fractions\n",
    "                    for s in np.arange(10):                 #loop through CBA salary steps\n",
    "                        for c in cbacols.keys():            #loop through salary matrix columns\n",
    "                            sal = self.get_salary(sy,s+1,cbacols[c])    #look up salary in CBA tables\n",
    "                            try:\n",
    "                                diff = abs(earnings - frac*sal/p)      #compute delta from earnings\n",
    "                            except TypeError:\n",
    "                                diff = 100000.0\n",
    "                            if (diff < min_abs_diff):       #if this is the smallest difference so far:\n",
    "                                min_abs_diff = diff         #save the smallest value\n",
    "                                fte = frac                  #save the FTE fraction\n",
    "                                mc = c                      #save the salary matrix column\n",
    "                                yr = sy                     #save the year used for the CBA salary\n",
    "                                salary = sal\n",
    "                                payments = p                #save the number of payments\n",
    "                                step_code = str(yr) + '-' + mc + '-' + str(s+1)  #construct the step code\n",
    "        dct['step'] = step_code                                 #save results in Teacher object textbox\n",
    "        dct['payments'] = payments\n",
    "        dct['fte'] = fte\n",
    "        dct['mindiff'] = round(min_abs_diff,4)\n",
    "        dct['salary'] = round(salary,0)\n",
    "\n",
    "        return(dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### personnel classes\n",
    "\n",
    "provides functionality related to HR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():                                                         #generic employee class\n",
    "    def __init__(self,name):                                            #constructor\n",
    "        self.name = name\n",
    "        self.payperiods = {}\n",
    "        return\n",
    "        \n",
    "    def add_check(self,check_date,check):\n",
    "        if check_date not in self.payperiods.keys():\n",
    "            self.payperiods[check_date] = {}\n",
    "        check_seq = 1+len(self.payperiods[check_date])\n",
    "        self.payperiods[check_date][check_seq] = check\n",
    "        return\n",
    "    \n",
    "    def get_name(self):                                                 #return name of person\n",
    "        return(self.name)\n",
    "    \n",
    "    def get_payperiods(self):\n",
    "        return(self.payperiods)\n",
    "    \n",
    "    def get_payperiod(self,check_date):\n",
    "        try:\n",
    "            return(self.payperiods[check_date])\n",
    "        except IndexError:\n",
    "            return({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pdf and create a dictionary with the contents of each text box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function read_pdf() reads a PDF and returns a dictionary containing the contents\n",
    "\n",
    "Strategy for this document:  \n",
    "\n",
    "Save information from each element in the LTTextBox objects in a dictionary including:\n",
    "\n",
    "- x0 horizontal coordinate of the upper left corner of the text box\n",
    "- x1 horizontal coordinate of the lower right corner of the text box\n",
    "- y0 vertical coordinate of the upper left corner of the text box\n",
    "- y1 vertical coordinate of the lower right corner of the text box\n",
    "- page number \n",
    "- sequence number of text box within this page\n",
    "- text contained in the text box, converted to ascii\n",
    "\n",
    "Parsing the text is complicated by the fact that that a text box may span multiple columns and/or rows, and the text box groupings vary quite a bit depending on the page contents and layout.\n",
    "\n",
    "However, with a bit of luck the structure of the document will allow the contents to be deciphered with the following heuristics:\n",
    "\n",
    "- Text boxes containing left justified columns will tend to have nearly the same x0 coordinates\n",
    "- Text boxes containing right justified columns will tend to have nearly the same x1 coordinates\n",
    "- The codes for fund, account code, and object code are numeric and have fixed lengths\n",
    "- Extraneous information is often preceded or followed by a series of underscore and newline characters\n",
    "- Last name can be distinguished because is the only field that is all characters followed by a comma\n",
    "- Last name may be preceded by between one and three numerical fields:  fund, account, object.  If it is, the x0 value is shifted to the left.\n",
    "    - Three numerical fields precede the name:  assume they are fund, account, object\n",
    "    - Two numerical fields precede the name: assume they are account, object\n",
    "    - One numerical field precedes the name: assume it is object\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    document = open(path, 'rb')                                     #read a pdf and create a document object\n",
    "    rsrcmgr = PDFResourceManager()                                  #create a resource manager\n",
    "    laparams = LAParams()                                           #set the parameters for analysis\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)          #create a PDF page aggregator object\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    pdf={}                                                          #dictionary to hold the results\n",
    "\n",
    "    pageno = -1                                                     #initialize page coounter to zero\n",
    "\n",
    "    for page in PDFPage.get_pages(document):                        #loop through the pdf page by page\n",
    "        pageno = pageno + 1                                         #increment the page number\n",
    "        pdf[pageno] = {}                                            #dictionary for this page\n",
    "        interpreter.process_page(page)                              # receive the LTPage object for the page.\n",
    "        layout = device.get_result()                                # create layout object\n",
    "        tbox_no=0                                                   # index for element number\n",
    "        for element in layout:\n",
    "            if (type(element).__name__=='LTTextBoxHorizontal'):     #loop through text boxes\n",
    "                tbox_no += 1                                        #increment text box number\n",
    "                pdf[pageno][tbox_no] = {}                           #dictionary for text boxes within page\n",
    "                x0 = round(element.x0,2)                            #x0 coordinate of textbox corner\n",
    "                x1 = round(element.x1,2)                            #x1 coordinate of textbox corner\n",
    "                y0 = round(element.y0,2)                            #y0 coordinate of textbox corner\n",
    "                y1 = round(element.y1,2)                            #y1 coordinate of textbox corner\n",
    "                txt = element.get_text().encode('ascii', 'ignore')  #text converted to ascii\n",
    "                pdf[pageno][tbox_no]['x0'] = x0                     #create x0 coordinate entry\n",
    "                pdf[pageno][tbox_no]['x1'] = x1                     #create x1 coordinate entry\n",
    "                pdf[pageno][tbox_no]['y0'] = y0                     #create y0 coordinate entry\n",
    "                pdf[pageno][tbox_no]['y1'] = y1                     #create y1 coordinate entry\n",
    "\n",
    "                pdf[pageno][tbox_no]['text'] = ''.join(chr(c) for c in txt) #convert bytes to string\n",
    "    return(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the commas from earnings and rate values\n",
    "\n",
    "def remove_commas(st):\n",
    "    newstr = st.replace(',','')                     #remove commas from string\n",
    "    return(newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the headings fields \n",
    "\n",
    "def remove_headings(st):\n",
    "    lines = st.split('\\n')                         #split the string at newline characters '\\n'\n",
    "    for line in lines:                             #loop through the resulting lines\n",
    "        if (line.startswith('FUND ') |\\\n",
    "           (line.startswith('POSITION')) |\\\n",
    "           (line.startswith('RATE')) |\\\n",
    "           (line.startswith('ACCT-')) |\\\n",
    "           (line.startswith('CHECK')) |\\\n",
    "           (line.startswith('_'))):                #check for strings that appear only in headings\n",
    "            try:\n",
    "                newline_index = st.index('\\n')     #if present, remove this line from the text string\n",
    "                st = st[newline_index+1:]\n",
    "            except ValueError:\n",
    "                print('Value Error',st)            #recover from Value Error and print string\n",
    "        else:\n",
    "            return(st)                             #if no headings, just return\n",
    "    return('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the FY2017 earnings report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p17 = read_pdf('../FY17 Gene_Redacted.pdf')\n",
    "p17 = read_pdf('../FY17 Gene.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the FY2018 earnings report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p18 = read_pdf('../FY18 Gene_Redacted.pdf')\n",
    "p18 = read_pdf('../FY18 Gene.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dictionary with only those text boxes containing names\n",
    "\n",
    "Use the following algorithm to identify text boxes that contain names:\n",
    "\n",
    "- x0, horizontal coordinate of the upper left corner of the text box, is less than 162\n",
    "- the text string contains at least one comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(dct):\n",
    "\n",
    "    dnames = {}\n",
    "\n",
    "    fund = ''\n",
    "    acct = ''\n",
    "    obj  = ''\n",
    "    \n",
    "    for page in sorted(dct.keys()):                                #loop through text box dictionary by page # \n",
    "        if (page not in dnames.keys()):                            #page number is highest level key\n",
    "            dnames[page] = {}                                      #initialize entry for this page\n",
    "        for tb in sorted(dct[page].keys()):                        #loop through all text boxes on this page\n",
    "            if (dct[page][tb]['x0'] < 162.0):                      #those with names start to the left of x0=162\n",
    "                txt = str(dct[page][tb]['text'])                   #convert the 'text' element to a string\n",
    "                if (',' in txt):                                   #every name contains a comma\n",
    "                    txt = remove_headings(txt)\n",
    "                    lines = txt.split('\\n')                        #split text into lines\n",
    "                    words = lines[0].split()                       #split first line into words\n",
    "                    for word in words:                             #loop through and strip out fund, acct, obj\n",
    "                        if (word.isdigit()):\n",
    "                            if (len(word)==4):                     # 4 digits means fund\n",
    "                                fund = word\n",
    "                            if (len(word)==8):                     # 8 digits means acct-code\n",
    "                                acct = word\n",
    "                            if (len(word)==5):                     # 5 digits means obj\n",
    "                                obj = word\n",
    "                            txt = txt[len(word)+1:]                # remove fund/acct/obj from txt\n",
    "                    dnames[page][tb] = {}                          #initialize dictionary for this page\n",
    "                    dnames[page][tb]['x0'] = dct[page][tb]['x0']\n",
    "                    dnames[page][tb]['x1'] = dct[page][tb]['x1']\n",
    "                    dnames[page][tb]['y0'] = dct[page][tb]['y0']\n",
    "                    dnames[page][tb]['y1'] = dct[page][tb]['y1']\n",
    "                    dnames[page][tb]['fund'] = fund\n",
    "                    dnames[page][tb]['acct'] = acct\n",
    "                    dnames[page][tb]['obj'] = obj\n",
    "                    dnames[page][tb]['text'] = txt\n",
    "    return(dnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate text boxes that overlap on the vertical scale and contain names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_name_boxes(names):\n",
    "    newnames = {}\n",
    "    \n",
    "    for page in sorted(names.keys()):                                        #loop through pages of pdf\n",
    "        newnames[page] = {}                                                  #initialize new names dictionary\n",
    "        skip = make_array()                                                  #initialize list of boxes to skip\n",
    "    \n",
    "        for tb in sorted(names[page].keys()):                                #loop through text boxes on this page\n",
    "            for tb2 in sorted(names[page].keys()):                           #compare this one to the others\n",
    "                if ((tb2 > tb) & \\\n",
    "                    (names[page][tb]['y0'] <= names[page][tb2]['y1']) & \\\n",
    "                    (names[page][tb2]['y0'] <= names[page][tb]['y1'])):      \n",
    "                    d = {}                                                   #initialize replacement entry\n",
    "                    d['x0'] = names[page][tb]['x0']                          #keep x0    \n",
    "                    d['x1'] = names[page][tb2]['x1']                         #replace x1 with tb2 value\n",
    "                    d['y0'] = names[page][tb2]['y0']                         #replace y0 with tb2 value\n",
    "                    d['y1'] = names[page][tb]['y1']                          #keep y1 value\n",
    "                    d['text'] = names[page][tb]['text'] +\\\n",
    "                        names[page][tb2]['text']                             #contatenate text strings\n",
    "                    d['fund'] = names[page][tb]['fund']                      #copy fund, acct, and obj\n",
    "                    d['acct'] = names[page][tb]['acct']\n",
    "                    d['obj'] = names[page][tb]['obj']\n",
    "                    newnames[page][tb2] = d                                  #plug into dictionary\n",
    "                    skip = np.append(skip,tb)                                #add old boxes to skip list\n",
    "                    skip = np.append(skip,tb2)\n",
    "            if (tb not in skip):                                             #if no match, check skip list \n",
    "                newnames[page][tb] = names[page][tb]                         #just copy if not in skip list\n",
    "                    \n",
    "    return(newnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combdd(cn,pdf):\n",
    "    \n",
    "    dd = {}\n",
    "    \n",
    "    for page in sorted(cn.keys()):\n",
    "        if page not in dd.keys():\n",
    "            dd[page] = {}\n",
    "        for tb in sorted(cn[page].keys()):                               #loop through consolidated name textboxes\n",
    "            dd[page][tb] = cn[page][tb]\n",
    "            y0  = dd[page][tb]['y0']                                      #extract vertical coordinates\n",
    "            y1  = dd[page][tb]['y1']\n",
    "            txt = dd[page][tb]['text']                           #extract text\n",
    "            for tb2 in sorted(pdf[page].keys()):                            #loop through the other boxes in pdf\n",
    "                if (tb != tb2):                                             #ignore if same box as names\n",
    "                    tx0 = pdf[page][tb2]['x0']                              #get horizontal offset\n",
    "                    ty0 = pdf[page][tb2]['y0']                              #check whether the vertical \n",
    "                    ty1 = pdf[page][tb2]['y1']                              #range of this box overlaps that\n",
    "                    if ((y0 <= ty1) & (ty0 <= y1)):                         #of the name box\n",
    "                        txt = remove_headings(pdf[page][tb2]['text'])\n",
    "                        if ((312.0 < tx0) & (tx0 < 316.0)):                 #match to DATE/NUMBER\n",
    "                            dd[page][tb]['numbers1'] = txt\n",
    "                        if ((383.0 < tx0) & (tx0 < 395.0)):                 #match to NUMBER\n",
    "                            if 'numbers2' not in dd[page][tb].keys():\n",
    "                                dd[page][tb]['numbers2'] = txt\n",
    "                            else:\n",
    "                                dd[page][tb]['numbers2'] += txt\n",
    "                        if ((437.0 < tx0) & (tx0 < 440.0)):                 #match to POSITION\n",
    "                            dd[page][tb]['positions'] = txt\n",
    "                        if ((509.0 < tx0) & (tx0 < 533.0)):                 #match to RATE \n",
    "                            dd[page][tb]['rates'] = remove_commas(txt)\n",
    "                        if ((558.0 < tx0) & (tx0 < 630.0)):                 #match to ACCT-EARNINGS\n",
    "                            dd[page][tb]['earnings'] = remove_commas(txt)\n",
    "\n",
    "    return(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(nn):\n",
    "    \n",
    "    lld = {}\n",
    "    \n",
    "    for page in sorted(nn.keys()):\n",
    "        if page not in lld.keys():\n",
    "            lld[page] = {}\n",
    "        for tb in sorted(nn[page].keys()):\n",
    "            if tb not in lld[page].keys():\n",
    "                lld[page][tb]              = {}\n",
    "                lld[page][tb]['names']     = []\n",
    "                lld[page][tb]['checks']    = []\n",
    "                lld[page][tb]['dates']     = []\n",
    "                lld[page][tb]['rates']     = []\n",
    "                lld[page][tb]['earnings']  = []\n",
    "                lld[page][tb]['positions'] = []\n",
    "                lld[page][tb]['fund']      = ''\n",
    "                lld[page][tb]['acct']      = ''\n",
    "                lld[page][tb]['obj']       = ''\n",
    "            txt = nn[page][tb]['text']\n",
    "            words = txt.split('\\n')\n",
    "            for word in words:\n",
    "                if (len(word) > 1):\n",
    "                    lld[page][tb]['names'].append(word)\n",
    "            if 'numbers1' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['numbers1']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if word.isdigit():\n",
    "                        lld[page][tb]['checks'].append(word)\n",
    "                    elif '/' in word:\n",
    "                        lld[page][tb]['dates'].append(word)\n",
    "            if 'numbers2' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['numbers2']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if word.isdigit():\n",
    "                        lld[page][tb]['checks'].append(word)\n",
    "            if 'rates' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['rates']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if '.' in word:\n",
    "                        lld[page][tb]['rates'].append(float(word))\n",
    "            if 'positions' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['positions']\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if len(word)>1:\n",
    "                        lld[page][tb]['positions'].append(word)\n",
    "            if 'fund' in nn[page][tb].keys():\n",
    "                lld[page][tb]['fund'] = nn[page][tb]['fund']\n",
    "            if 'acct' in nn[page][tb].keys():\n",
    "                lld[page][tb]['acct'] = nn[page][tb]['acct']\n",
    "            if 'obj' in nn[page][tb].keys():\n",
    "                lld[page][tb]['obj'] = nn[page][tb]['obj']\n",
    "            if 'earnings' in nn[page][tb].keys():\n",
    "                txt = nn[page][tb]['earnings']\n",
    "                had_underscore = False\n",
    "                words = txt.split('\\n')\n",
    "                for word in words:\n",
    "                    if '.' in word:\n",
    "                        if not had_underscore: \n",
    "                            lld[page][tb]['earnings'].append(float(word))\n",
    "                            had_underscore = False\n",
    "                    elif '_' in word:\n",
    "                        had_underscore = True\n",
    "            if (len(lld[page][tb]['checks']) < len(lld[page][tb]['dates'])):\n",
    "                new_checks = []\n",
    "                check_index = 0\n",
    "                for i in np.arange(len(lld[page][tb]['earnings'])):\n",
    "                    if (lld[page][tb]['earnings'][i] > 0.0):\n",
    "                        new_checks.append(lld[page][tb]['checks'][check_index])\n",
    "                        check_index += 1\n",
    "                    else:\n",
    "                        new_checks.append('gen'+str(page) + '-' + str(tb) + '-' + str(i))\n",
    "                        print(\"inserting check number: \",page,tb,i)\n",
    "                lld[page][tb]['checks'] = new_checks\n",
    "    return(lld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the earnings reports and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_earnings(pdf):\n",
    "    nnd = get_names(pdf)\n",
    "    cnd = consolidate_name_boxes(nnd)\n",
    "    newnames = combdd(cnd,pdf)\n",
    "    lld = get_lines(newnames)\n",
    "    return(lld)\n",
    "\n",
    "ll={}\n",
    "\n",
    "ll[2017] = process_earnings(p17)\n",
    "ll[2018] = process_earnings(p18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check earnings against totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totearn = {}\n",
    "\n",
    "for year in ll.keys():\n",
    "    if year not in totearn.keys():\n",
    "        totearn[year] = 0.0\n",
    "    for page in ll[year].keys():\n",
    "        for tb in ll[year][page].keys():\n",
    "            for amt in ll[year][page][tb]['earnings']:\n",
    "                totearn[year] += amt\n",
    "                \n",
    "print(round(totearn[2017],2))       #FY2017 earnings report total is $22,608,024.34\n",
    "print(round(totearn[2018],2))       #FY2018 earnings report total is $22,409,915.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = {}\n",
    "\n",
    "pp = payperiod()          #get end dates of payroll periods\n",
    "\n",
    "egacct = EG_acct_codes()   #EG acct codes\n",
    "\n",
    "rideobj = RIDE_Obj_labels()\n",
    "\n",
    "sm = teacher_salary_matrix()\n",
    "\n",
    "paydays = pp.get_payperiods()\n",
    "\n",
    "for year in ll.keys():\n",
    "    for page in ll[year].keys():\n",
    "        for tb in ll[year][page].keys():\n",
    "            check_numbers = ll[year][page][tb]['checks']\n",
    "            names         = ll[year][page][tb]['names']\n",
    "            check_dates   = ll[year][page][tb]['dates']\n",
    "            fund          = ll[year][page][tb]['fund']\n",
    "            acct          = ll[year][page][tb]['acct']\n",
    "            obj           = ll[year][page][tb]['obj']\n",
    "            positions     = ll[year][page][tb]['positions']\n",
    "            rates         = ll[year][page][tb]['rates']\n",
    "            earnings      = ll[year][page][tb]['earnings']\n",
    "            obj_desc      = rideobj.get_obj_desc(int(obj))\n",
    "            acct_desc     = egacct.get_eg_acct_desc(acct)\n",
    "            acct_UCOA     = egacct.get_eg_acct_UCOA(acct)\n",
    "            \n",
    "            for i in np.arange(len(check_numbers)):\n",
    "                \n",
    "                check_number    = check_numbers[i]\n",
    "                name            = names[i]\n",
    "                date_str        = check_dates[i]\n",
    "                position        = positions[i]\n",
    "                rate            = rates[i]\n",
    "                earned          = earnings[i]\n",
    "                \n",
    "                words = date_str.split('/')\n",
    "                check_date   = date(int(words[2]),int(words[0]),int(words[1]))\n",
    "                if (check_date not in paydays.keys()):\n",
    "                    new_date = pp.get_previous_payday(check_date)\n",
    "                    print('adjusting date',name,check_date,new_date)\n",
    "                    check_date = new_date\n",
    "                stepdata = sm.decode_earnings(check_date,rate,earned,pp)\n",
    "                if (len(stepdata['step']) < 1):\n",
    "                    stepdata={}\n",
    "                if check_number not in checks.keys():\n",
    "                    checks[check_number] = pay_check(check_number,name,check_date,pp)\n",
    "\n",
    "                checks[check_number].add_item(fund,acct,obj,position,rate,earned, \\\n",
    "                            acct_desc,obj_desc,acct_UCOA,stepdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earns = {}\n",
    "\n",
    "for check in checks.keys():\n",
    "    check_date = checks[check].get_date()\n",
    "    if check_date not in earns.keys():\n",
    "        earns[check_date] = 0.0\n",
    "    itms = checks[check].get_items()\n",
    "    for item in itms.keys():\n",
    "        earns[check_date] += itms[item]['earnings']\n",
    "    \n",
    "for ckdate in sorted(earns.keys()):\n",
    "    print(ckdate,round(earns[ckdate],2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = {}\n",
    "\n",
    "for ckno in checks.keys():\n",
    "    ck   = checks[ckno]\n",
    "    name = ck.get_name()\n",
    "    ckdate = ck.get_date()\n",
    "    if name not in people.keys():\n",
    "        people[name] = Person(name)\n",
    "    people[name].add_check(ckdate,ck)\n",
    "        \n",
    "len(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in people.keys():\n",
    "    paydays = people[name].get_payperiods()\n",
    "    print(name)\n",
    "    for ckdate in paydays.keys():\n",
    "        print('    ',ckdate)\n",
    "        for seq in paydays[ckdate].keys():\n",
    "            check = paydays[ckdate][seq]\n",
    "            cknum = check.get_number()\n",
    "            items = check.get_items()\n",
    "            print('        ',seq,cknum,items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retirees = ['MALLOZZI, JOANN S','HADFIELD, RENEE M','KOWAL, MAUREEN E','JOHNSON, TRESSA', \\\n",
    "           'DEPASQUALE, HELEN L','CAVANAUGH, JUDITH L']\n",
    "\n",
    "for name in retirees:\n",
    "    ck = people[name].get_payperiod(date(2018,5,25))\n",
    "    itms = ck[1].get_items()\n",
    "    step = itms[1]\n",
    "    print(name, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine distribution of steps for new hires\n",
    "\n",
    "Anyone whose first paycheck occurs after 8/15/2016 is assumed to have been hired in for FY2017 or FY2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdct = {}\n",
    "\n",
    "for name in people.keys():\n",
    "    if name not in pdct.keys():\n",
    "        pdct[name] = {}\n",
    "        pdct[name]= {'dt':date(2020,1,1),'step':'unk','payments':0,'mindiff':100.0}\n",
    "    p = people[name].get_payperiods()\n",
    "    for d in p.keys():\n",
    "        for i in p[d].keys():\n",
    "            itms = p[d][i].get_items()\n",
    "            for j in itms.keys():\n",
    "                if ('TEACHER' in itms[j]['position']):\n",
    "                    if (len(itms[j]['step_info']) > 1):\n",
    "                        step = itms[j]['step_info']['step']\n",
    "                        pmts = itms[j]['step_info']['payments']\n",
    "                        mindiff = itms[j]['step_info']['mindiff']\n",
    "                        if (d < pdct[name]['dt']):\n",
    "                            pdct[name]['dt'] = d\n",
    "                            pdct[name]['step'] = step\n",
    "                            pdct[name]['payments'] = pmts\n",
    "                            pdct[name]['mindiff'] = mindiff\n",
    "                        \n",
    "steps = {}\n",
    "                    \n",
    "for name in pdct.keys():\n",
    "    if ((pdct[name]['dt'] > date(2016,8,15)) & \\\n",
    "        (pdct[name]['dt'] < date(2019,1,1)) & \\\n",
    "        (pdct[name]['mindiff'] < 0.5) & \\\n",
    "        (pdct[name]['payments'] > 22.0)) :\n",
    "        print(name,pdct[name]['dt'],pdct[name]['step'],pdct[name]['payments'],pdct[name]['mindiff'])\n",
    "        step = pdct[name]['step'] \n",
    "        if step not in steps.keys():\n",
    "            steps[step] = 0\n",
    "        steps[step]+=1\n",
    "\n",
    "print(len(steps))       \n",
    "        \n",
    "steps          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}  #positions\n",
    "\n",
    "for check in checks.keys():\n",
    "    ck = checks[check]\n",
    "    name = ck.get_name()\n",
    "    cdate = ck.get_date()\n",
    "    items=ck.get_items()\n",
    "    for itm in items.keys():\n",
    "        pos = items[itm]['position']\n",
    "        if (pos == 'TEACHER'):\n",
    "            if name not in p.keys():\n",
    "                p[name] = {}\n",
    "                p[name]['min'] = cdate\n",
    "                p[name]['max'] = cdate\n",
    "                p[name]['step'] = 'unk'\n",
    "            else:\n",
    "                if (cdate < p[name]['min']):\n",
    "                    p[name]['min'] = cdate\n",
    "                if (cdate > p[name]['max']):\n",
    "                    p[name]['max'] = cdate\n",
    "                    \n",
    "first_date = date(2016,8,15)\n",
    "last_date  = date(2018,6,22)\n",
    "for name in p.keys():\n",
    "    mindate = p[name]['min']\n",
    "    if (mindate > first_date):\n",
    "        pc = people[name].get_payperiod(mindate)\n",
    "        pci = pc[1].get_items()\n",
    "        print(name,pci[1]['step_info'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
